{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Custom Sklearn Pipeline\n",
    "> How to include custom data preprocessing steps in an sklearn pipeline. \n",
    "\n",
    "In this notebook we will import the [income classification dataset](https://www.kaggle.com/lodetomasi1995/income-classification/data), review common preprocessing steps, and then introduce how those steps can be included in an sklearn pipeline. \n",
    "\n",
    "![](https://media.giphy.com/media/Jwp4sxM0Rjk1W/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:08.195898Z",
     "start_time": "2020-10-09T06:24:07.054075Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Transformers\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Modeling Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Transformers\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Modeling Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:08.267053Z",
     "start_time": "2020-10-09T06:24:08.197530Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/income.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education       marital_status  \\\n",
       "0    0          State-gov   Bachelors        Never-married   \n",
       "1    1   Self-emp-not-inc   Bachelors   Married-civ-spouse   \n",
       "2    0            Private     HS-grad             Divorced   \n",
       "3    1            Private        11th   Married-civ-spouse   \n",
       "4    0            Private   Bachelors   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race      sex  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male             1   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income  \n",
       "0             0              40   United-States       0  \n",
       "1             0              13   United-States       0  \n",
       "2             0              40   United-States       0  \n",
       "3             0              40   United-States       0  \n",
       "4             0              40            Cuba       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "df = pd.read_csv('data/income.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakout Rooms\n",
    "\n",
    "\n",
    "### Group 1\n",
    "\n",
    "Write a function called `bin_middle_age` that can be applied to the `age` column and returns a 1 if the age is 45-64 and a zero for every other age. \n",
    "\n",
    "### Group 2\n",
    "\n",
    "Write a function called `bin_capital` that can be applied to the `capital_gain` and `capital_loss` columns and returns a 1 if the input is more than zero and a 0 for anything else.\n",
    "\n",
    "### Group 3\n",
    "\n",
    "Please write code to fit a one hot encoder to all of the object datatypes. Transform the object columns and turn them into a dataframe. For this final step, I'll give you two clues: \"sparse\" and \"dense\". Only one of them will be needed.\n",
    "\n",
    "### Group 4\n",
    "\n",
    "Please write code to scale the `'hours_per_week'` column. Because you are scaling, please write code that does not lead to data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 1\n",
    "def bin_middle_age(age):\n",
    "    pass\n",
    "\n",
    "df['age'] = df.age.apply(bin_middle_age)\n",
    "\n",
    "# Group 2\n",
    "def bin_capital(x):\n",
    "    pass\n",
    "\n",
    "df['capital_gain'] = df.capital_gain.apply(bin_capital)\n",
    "df['capital_loss'] = df.capital_loss.apply(bin_capital)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('income', axis = 1), \n",
    "                                                    df.income,\n",
    "                                                    random_state = 2020)  \n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Group 3\n",
    "    pass\n",
    "\n",
    "# Group 4\n",
    "    pass\n",
    "\n",
    "\n",
    "modeling_df = pd.concat([X_train.age, X_train.capital_gain, X_train.capital_loss, \n",
    "                         hours_per_week, categoricals], axis = 1)\n",
    "\n",
    "modeling_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:08.429252Z",
     "start_time": "2020-10-09T06:24:08.269876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>x0_ ?</th>\n",
       "      <th>x0_ Federal-gov</th>\n",
       "      <th>x0_ Local-gov</th>\n",
       "      <th>x0_ Never-worked</th>\n",
       "      <th>x0_ Private</th>\n",
       "      <th>x0_ Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_ Portugal</th>\n",
       "      <th>x7_ Puerto-Rico</th>\n",
       "      <th>x7_ Scotland</th>\n",
       "      <th>x7_ South</th>\n",
       "      <th>x7_ Taiwan</th>\n",
       "      <th>x7_ Thailand</th>\n",
       "      <th>x7_ Trinadad&amp;Tobago</th>\n",
       "      <th>x7_ United-States</th>\n",
       "      <th>x7_ Vietnam</th>\n",
       "      <th>x7_ Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.656074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.252169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  capital_gain  capital_loss  hours_per_week  x0_ ?  x0_ Federal-gov  \\\n",
       "0    0             0             0        0.767358    0.0              0.0   \n",
       "1    0             0             0       -1.656074    0.0              0.0   \n",
       "2    0             0             0       -1.252169    0.0              0.0   \n",
       "3    0             0             0       -0.040453    0.0              0.0   \n",
       "4    0             0             0       -0.040453    0.0              0.0   \n",
       "\n",
       "   x0_ Local-gov  x0_ Never-worked  x0_ Private  x0_ Self-emp-inc  ...  \\\n",
       "0            0.0               0.0          1.0               0.0  ...   \n",
       "1            0.0               0.0          1.0               0.0  ...   \n",
       "2            0.0               0.0          1.0               0.0  ...   \n",
       "3            0.0               0.0          1.0               0.0  ...   \n",
       "4            0.0               0.0          1.0               0.0  ...   \n",
       "\n",
       "   x7_ Portugal  x7_ Puerto-Rico  x7_ Scotland  x7_ South  x7_ Taiwan  \\\n",
       "0           0.0              0.0           0.0        0.0         0.0   \n",
       "1           0.0              0.0           0.0        0.0         0.0   \n",
       "2           0.0              0.0           0.0        0.0         0.0   \n",
       "3           0.0              0.0           0.0        0.0         0.0   \n",
       "4           0.0              0.0           0.0        0.0         0.0   \n",
       "\n",
       "   x7_ Thailand  x7_ Trinadad&Tobago  x7_ United-States  x7_ Vietnam  \\\n",
       "0           0.0                  0.0                1.0          0.0   \n",
       "1           0.0                  0.0                1.0          0.0   \n",
       "2           0.0                  0.0                1.0          0.0   \n",
       "3           0.0                  0.0                1.0          0.0   \n",
       "4           0.0                  0.0                1.0          0.0   \n",
       "\n",
       "   x7_ Yugoslavia  \n",
       "0             0.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             0.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "# Group 1\n",
    "def bin_middle_age(age):\n",
    "    if age < 45:\n",
    "        return 0 \n",
    "    elif age > 64:\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "df['age'] = df.age.apply(bin_middle_age)\n",
    "\n",
    "# Group 2\n",
    "def bin_capital(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['capital_gain'] = df.capital_gain.apply(bin_capital)\n",
    "df['capital_loss'] = df.capital_loss.apply(bin_capital)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('income', axis = 1), \n",
    "                                                    df.income,\n",
    "                                                    random_state = 2020)  \n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Group 3\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "categoricals = hot_encoder.fit_transform(X_train.select_dtypes(object))\n",
    "categoricals = pd.DataFrame(categoricals, columns = hot_encoder.get_feature_names())\n",
    "\n",
    "# Group 4\n",
    "hours_scaler = StandardScaler()\n",
    "hours_per_week = hours_scaler.fit_transform(X_train['hours_per_week'].values.reshape(-1,1))\n",
    "hours_per_week = pd.DataFrame(hours_per_week, columns = ['hours_per_week'])\n",
    "\n",
    "\n",
    "modeling_df = pd.concat([X_train.age, X_train.capital_gain, X_train.capital_loss, \n",
    "                         hours_per_week, categoricals], axis = 1)\n",
    "\n",
    "modeling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move all of this into a Pipeline\n",
    "\n",
    "Above we used two sklearn transformers and two custom functions to format our dataframe. This means, that we will need to create two custom transformers. The sklearn transformers can be used as they are.\n",
    "\n",
    "To do this, we will create a class called `BinAge` that inherits from the sklearn classes, `TransformerMixin` and `BaseEstimator`. This class should have the following methods:\n",
    "1. `__init__`\n",
    "    - This method only needs to exist. No code needs to be added to the method.\n",
    "2. `fit`\n",
    "    - This method should have three arguments\n",
    "        1. self\n",
    "        2. `X`.\n",
    "        3. `y=None`\n",
    "    - This method should return `self`.\n",
    "3. `_bin_data`\n",
    "    - This method is our function for binning the age column\n",
    "4. `_to_df`\n",
    "    - This is a helper function to transform the data to a dataframe.\n",
    "    - This method should check if the input is a dataframe and return a dataframe\n",
    "5. `transform`\n",
    "    - This method should have two arguments\n",
    "        1. self\n",
    "        2. `X`\n",
    "    - This method should turn X to a dataframe. \n",
    "    - This method should apply the `_bin_data` method\n",
    "    - Return the binned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinAge():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:08.439645Z",
     "start_time": "2020-10-09T06:24:08.431345Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "class BinAge(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _bin_data(self, x):\n",
    "        if x < 45 or x > 64:\n",
    "            return 0 \n",
    "        else: \n",
    "            return 1\n",
    "        \n",
    "    def _to_df(self, X):\n",
    "        if type(X) != pd.DataFrame:\n",
    "            data = pd.DataFrame([X], index=len([X]))\n",
    "        else:\n",
    "            data = X.copy()\n",
    "        return data\n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = self._to_df(X)\n",
    "        data = data.applymap(self._bin_data)\n",
    "        \n",
    "        return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now repeat the process for a `BinCapital` Transformer!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinCapital():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "class BinCapital(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _bin_data(self, x):\n",
    "        if x > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def _to_df(self, X):\n",
    "        if type(X) != pd.DataFrame:\n",
    "            data = pd.DataFrame([X], index=len([X]))\n",
    "        else:\n",
    "            data = X.copy()\n",
    "        return data\n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = self._to_df(X)\n",
    "        data = data.applymap(self._bin_data)\n",
    "        return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "\n",
    "To make this pipeline, we will use the following sklearn functions:\n",
    "\n",
    "1. `make_column_transformer`\n",
    "> This function receives \"Tuples of the form `(transformer, [columns])` specifying the transformer objects to be applied to subsets of the data.\"\n",
    "2. `make_column_selector`\n",
    "> \"Selects columns based on datatype or the columns name with a regex. When using multiple selection criteria, all criteria must match for a column to be selected.\"\n",
    "3. `make_pipeline`\n",
    "> Used to create a pipeline of inputer transformer and estimator objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:08.447204Z",
     "start_time": "2020-10-09T06:24:08.441626Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing = make_column_transformer((BinAge(), ['age']),\n",
    "                                      (BinCapital(), ['capital_gain']),\n",
    "                                      (BinCapital(), ['capital_loss']),\n",
    "                                      (OneHotEncoder(),\n",
    "                                       make_column_selector(dtype_include=object)),\n",
    "                                      (StandardScaler(), ['hours_per_week']),\n",
    "                                      remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "preprocessing = make_column_transformer((BinAge(), ['age']),\n",
    "                                      (BinCapital(), ['capital_gain']),\n",
    "                                      (BinCapital(), ['capital_loss']),\n",
    "                                      (OneHotEncoder(),\n",
    "                                       make_column_selector(dtype_include=object)),\n",
    "                                      (StandardScaler(), ['hours_per_week']),\n",
    "                                      remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all of our preprocessing can be done with the `fit_transform` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:08.568196Z",
     "start_time": "2020-10-09T06:24:08.449203Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21978x105 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 200636 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up pipeline, we can add a machine learning model to a new pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:08.573630Z",
     "start_time": "2020-10-09T06:24:08.570169Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_pipeline = make_pipeline(preprocessing, DecisionTreeClassifier())\n",
    "rf_pipeline = make_pipeline(preprocessing, RandomForestClassifier(max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "dt_pipeline = make_pipeline(preprocessing, DecisionTreeClassifier())\n",
    "rf_pipeline = make_pipeline(preprocessing, RandomForestClassifier(max_depth=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our pipelines are built!\n",
    "\n",
    "Now we can run them through cross validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:10.975119Z",
     "start_time": "2020-10-09T06:24:08.577326Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_score(dt_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80823476, 0.79026388, 0.80391265, 0.80705347, 0.79681456])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "cross_val_score(dt_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:19.168917Z",
     "start_time": "2020-10-09T06:24:10.978359Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_score(rf_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83575978, 0.83484986, 0.83371247, 0.83390216, 0.83526735])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "cross_val_score(rf_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:21.468664Z",
     "start_time": "2020-10-09T06:24:19.170841Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipeline.fit(X_train, y_train)\n",
    "train_preds = rf_pipeline.predict(X_train)\n",
    "test_preds = rf_pipeline.predict(X_test)\n",
    "print(f'Training Accuracy: {accuracy_score(y_train, train_preds)}')\n",
    "print(f'Testing Accuracy: {accuracy_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8458003458003458\n",
      "Testing Accuracy: 0.8390663390663391\n"
     ]
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "train_preds = rf_pipeline.predict(X_train)\n",
    "test_preds = rf_pipeline.predict(X_test)\n",
    "print(f'Training Accuracy: {accuracy_score(y_train, train_preds)}')\n",
    "print(f'Testing Accuracy: {accuracy_score(y_test, test_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can fit the final pipeline on all of the data and test it on an additional hold out set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:24.068866Z",
     "start_time": "2020-10-09T06:24:21.470835Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipeline.fit(df.drop('income', axis = 1), df.income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('binage', BinAge(), ['age']),\n",
       "                                                 ('bincapital-1', BinCapital(),\n",
       "                                                  ['capital_gain']),\n",
       "                                                 ('bincapital-2', BinCapital(),\n",
       "                                                  ['capital_loss']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7fa21d2f43d0>),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['hours_per_week'])])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=10))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "rf_pipeline.fit(df.drop('income', axis = 1), df.income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the hold out set and make predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T06:24:24.174775Z",
     "start_time": "2020-10-09T06:24:24.070864Z"
    }
   },
   "outputs": [],
   "source": [
    "validation = pd.read_csv('data/validation_features.csv')\n",
    "val_preds = rf_pipeline.predict(validation)\n",
    "y_val = pd.read_csv('data/validation_target.csv').iloc[:,0]\n",
    "accuracy_score(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449017199017199"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "validation = pd.read_csv('data/validation_features.csv')\n",
    "val_preds = rf_pipeline.predict(validation)\n",
    "y_val = pd.read_csv('data/validation_target.csv').iloc[:,0]\n",
    "accuracy_score(y_val, val_preds)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
