{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Custom Sklearn Pipeline\n",
    "> How to include custom data preprocessing steps in an sklearn pipeline. \n",
    "\n",
    "In this notebook we will import the [income classification dataset](https://www.kaggle.com/lodetomasi1995/income-classification/data), review common preprocessing steps, and then introduce how those steps can be included in an sklearn pipeline. \n",
    "\n",
    "![](https://media.giphy.com/media/Jwp4sxM0Rjk1W/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:15:56.267368Z",
     "start_time": "2021-11-17T04:15:56.251621Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Transformers\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Modeling Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pickle\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:15:56.907618Z",
     "start_time": "2021-11-17T04:15:56.902742Z"
    }
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# Standard Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Transformers\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Modeling Evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Pipelines\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pickle\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:15:57.715688Z",
     "start_time": "2021-11-17T04:15:57.631138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>283602</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>35864</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>Iran</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>146764</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>59380</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>338836</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  educational-num  \\\n",
       "0   53         Local-gov  283602       Masters               14   \n",
       "1   28  Self-emp-not-inc   35864  Some-college               10   \n",
       "2   29           Private  146764  Some-college               10   \n",
       "3   49           Private   59380  Some-college               10   \n",
       "4   51      Self-emp-inc  338836  Some-college               10   \n",
       "\n",
       "          marital-status       occupation   relationship   race  gender  \\\n",
       "0     Married-civ-spouse   Prof-specialty           Wife  White  Female   \n",
       "1     Married-civ-spouse  Exec-managerial        Husband  Other    Male   \n",
       "2               Divorced     Adm-clerical  Not-in-family  White  Female   \n",
       "3  Married-spouse-absent     Adm-clerical  Not-in-family  White  Female   \n",
       "4     Married-civ-spouse  Exec-managerial        Husband  White    Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0         15024             0              40  United-States   >50K  \n",
       "1             0             0              70           Iran   >50K  \n",
       "2             0             0              35  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40  United-States   >50K  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:15:58.440862Z",
     "start_time": "2021-11-17T04:15:58.357719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>283602</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>35864</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>Iran</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>146764</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>59380</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>338836</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt     education  educational-num  \\\n",
       "0   53         Local-gov  283602       Masters               14   \n",
       "1   28  Self-emp-not-inc   35864  Some-college               10   \n",
       "2   29           Private  146764  Some-college               10   \n",
       "3   49           Private   59380  Some-college               10   \n",
       "4   51      Self-emp-inc  338836  Some-college               10   \n",
       "\n",
       "          marital-status       occupation   relationship   race  gender  \\\n",
       "0     Married-civ-spouse   Prof-specialty           Wife  White  Female   \n",
       "1     Married-civ-spouse  Exec-managerial        Husband  Other    Male   \n",
       "2               Divorced     Adm-clerical  Not-in-family  White  Female   \n",
       "3  Married-spouse-absent     Adm-clerical  Not-in-family  White  Female   \n",
       "4     Married-civ-spouse  Exec-managerial        Husband  White    Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0         15024             0              40  United-States   >50K  \n",
       "1             0             0              70           Iran   >50K  \n",
       "2             0             0              35  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40  United-States   >50K  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "df = pd.read_csv('data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a preprocessing strategy\n",
    "\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Write a function called `bin_middle_age` that can be applied to the `age` column in `X_train` and returns a 1 if the age is 45-64 and a zero for every other age. \n",
    "\n",
    "### Task 2\n",
    "\n",
    "Write a function called `bin_capital` that can be applied to the `capital-gain` and `capital-loss` columns in `X_train` and returns a 1 if the input is more than zero and a 0 for anything else.\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Please write code to fit a one hot encoder to all of the object datatypes. Transform the object columns in `X_train` and turn them into a dataframe. For this final step, I'll give you two clues: \"sparse\" and \"dense\". Only one of them will be needed.\n",
    "\n",
    "### Task 4\n",
    "\n",
    "Please write code to scale the `'hours-per-week'` column in `X_train'.\n",
    "\n",
    "### Task 5\n",
    "Merge the transformed features into a new dataframe called `modeling_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:15:59.793946Z",
     "start_time": "2021-11-17T04:15:59.731497Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('income', axis = 1), \n",
    "                                                    df.income,\n",
    "                                                    random_state = 2020)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Task 1\n",
    "# ===========================================\n",
    "def bin_middle_age(age):\n",
    "    pass\n",
    "\n",
    "X_train['age'] = X_train.age.apply(bin_middle_age)\n",
    "# ===========================================\n",
    "\n",
    "# Task 2\n",
    "# ===========================================\n",
    "def bin_capital(x):\n",
    "    pass\n",
    "\n",
    "X_train['capital-gain'] = X_train['capital-gain'].apply(bin_capital)\n",
    "X_train['capital-loss'] = X_train['capital-loss'].apply(bin_capital)\n",
    "\n",
    " \n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "# ===========================================\n",
    "\n",
    "# Task 3\n",
    "# ===========================================\n",
    "hot_encoder = None\n",
    "categoricals = None\n",
    "# ===========================================\n",
    "\n",
    "# Task 4\n",
    "# ===========================================\n",
    "hours_scaler = None\n",
    "hours_per_week = None\n",
    "# ===========================================\n",
    "\n",
    "# Task 5\n",
    "# ===========================================\n",
    "modeling_df = None\n",
    "# ==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:17:49.421169Z",
     "start_time": "2021-11-17T04:17:49.262014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>x0_?</th>\n",
       "      <th>x0_Federal-gov</th>\n",
       "      <th>x0_Local-gov</th>\n",
       "      <th>x0_Never-worked</th>\n",
       "      <th>x0_Private</th>\n",
       "      <th>x0_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>x7_Portugal</th>\n",
       "      <th>x7_Puerto-Rico</th>\n",
       "      <th>x7_Scotland</th>\n",
       "      <th>x7_South</th>\n",
       "      <th>x7_Taiwan</th>\n",
       "      <th>x7_Thailand</th>\n",
       "      <th>x7_Trinadad&amp;Tobago</th>\n",
       "      <th>x7_United-States</th>\n",
       "      <th>x7_Vietnam</th>\n",
       "      <th>x7_Yugoslavia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.877472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  capital-gain  capital-loss  hours-per-week  x0_?  x0_Federal-gov  \\\n",
       "0    0             0             1       -2.877472   0.0             0.0   \n",
       "1    1             0             0        0.775310   0.0             0.0   \n",
       "2    0             0             0        0.207100   0.0             0.0   \n",
       "3    0             0             0        0.775310   0.0             1.0   \n",
       "4    0             0             0       -0.036419   0.0             0.0   \n",
       "\n",
       "   x0_Local-gov  x0_Never-worked  x0_Private  x0_Self-emp-inc  ...  \\\n",
       "0           0.0              0.0         1.0              0.0  ...   \n",
       "1           0.0              0.0         1.0              0.0  ...   \n",
       "2           0.0              0.0         1.0              0.0  ...   \n",
       "3           0.0              0.0         0.0              0.0  ...   \n",
       "4           1.0              0.0         0.0              0.0  ...   \n",
       "\n",
       "   x7_Portugal  x7_Puerto-Rico  x7_Scotland  x7_South  x7_Taiwan  x7_Thailand  \\\n",
       "0          0.0             0.0          0.0       0.0        0.0          0.0   \n",
       "1          0.0             0.0          0.0       0.0        0.0          0.0   \n",
       "2          0.0             0.0          0.0       0.0        0.0          0.0   \n",
       "3          0.0             0.0          0.0       0.0        0.0          0.0   \n",
       "4          0.0             0.0          0.0       0.0        0.0          0.0   \n",
       "\n",
       "   x7_Trinadad&Tobago  x7_United-States  x7_Vietnam  x7_Yugoslavia  \n",
       "0                 0.0               1.0         0.0            0.0  \n",
       "1                 0.0               1.0         0.0            0.0  \n",
       "2                 0.0               1.0         0.0            0.0  \n",
       "3                 0.0               1.0         0.0            0.0  \n",
       "4                 0.0               1.0         0.0            0.0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.drop('income', axis = 1), \n",
    "                                                    df.income,\n",
    "                                                    random_state = 2020)  \n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Task 1\n",
    "# ===========================================\n",
    "def bin_middle_age(age):\n",
    "    return int(age >= 45 and age <= 64)\n",
    "\n",
    "X_train['age'] = X_train.age.apply(bin_middle_age)\n",
    "# ===========================================\n",
    "\n",
    "# Task 2\n",
    "# ===========================================\n",
    "def bin_capital(x):\n",
    "    return int(x > 0)\n",
    "\n",
    "X_train['capital-gain'] = X_train['capital-gain'].apply(bin_capital)\n",
    "X_train['capital-loss'] = X_train['capital-loss'].apply(bin_capital)\n",
    "# ===========================================\n",
    "\n",
    "# Task 3\n",
    "# ===========================================\n",
    "hot_encoder = OneHotEncoder(sparse=False)\n",
    "categoricals = hot_encoder.fit_transform(X_train.select_dtypes(object))\n",
    "categoricals = pd.DataFrame(categoricals, columns = hot_encoder.get_feature_names())\n",
    "# ===========================================\n",
    "\n",
    "# Task 4\n",
    "# ===========================================\n",
    "hours_scaler = StandardScaler()\n",
    "hours_per_week = hours_scaler.fit_transform(X_train['hours-per-week'].values.reshape(-1,1))\n",
    "hours_per_week = pd.DataFrame(hours_per_week, columns = ['hours-per-week'])\n",
    "# ===========================================\n",
    "\n",
    "# Task 5\n",
    "# ===========================================\n",
    "modeling_df = pd.concat([X_train.age, X_train['capital-gain'], X_train['capital-loss'], \n",
    "                         hours_per_week, categoricals], axis = 1)\n",
    "# ===========================================\n",
    "\n",
    "modeling_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move all of this into a Pipeline\n",
    "\n",
    "\n",
    "### Writing a custom transformer\n",
    "\n",
    "Above we used two sklearn transformers and two custom functions to format our dataframe. This means, that we will need to create two custom transformers. The sklearn transformers can be used as they are.\n",
    "\n",
    "To do this, we will create a class called `BinAge` that inherits from the sklearn classes, `TransformerMixin` and `BaseEstimator`. This class should have the following methods:\n",
    "\n",
    "1. `fit`\n",
    "    - This method should have three arguments\n",
    "        1. self\n",
    "        2. `X`.\n",
    "        3. `y=None`\n",
    "    - This method should return `self`.\n",
    "    \n",
    "1. `_bin_data`\n",
    "    - This method is our function for binning the age column\n",
    "    \n",
    "1. `transform`\n",
    "    - This method should have two arguments\n",
    "        1. self\n",
    "        2. `X`\n",
    "    - This method should apply the `_bin_data` method to `X`\n",
    "    - Return the binned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:17:51.536426Z",
     "start_time": "2021-11-17T04:17:51.522395Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import vectorize\n",
    "\n",
    "class BinAge():\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    @vectorize\n",
    "    def _bin_data(x):\n",
    "        return int(x >= 45 and x <= 64)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:25:09.143906Z",
     "start_time": "2021-11-17T04:25:09.134621Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "from numpy import vectorize\n",
    "\n",
    "class BinAge(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    @vectorize\n",
    "    def _bin_data(x):\n",
    "        return int(x >= 45 and x <= 64)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self._bin_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now repeat the process for a `BinCapital` Transformer!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:17:54.076023Z",
     "start_time": "2021-11-17T04:17:54.072651Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinCapital():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:25:10.506609Z",
     "start_time": "2021-11-17T04:25:10.502644Z"
    }
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "class BinCapital(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    @vectorize\n",
    "    def _bin_data(x):\n",
    "        return int(x > 0)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self._bin_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline\n",
    "\n",
    "To make this pipeline, we will use the following sklearn functions:\n",
    "\n",
    "1. `make_column_transformer`\n",
    "> This function receives \"Tuples of the form `(transformer, [columns])` specifying the transformer objects to be applied to subsets of the data.\"\n",
    "2. `make_column_selector`\n",
    "> \"Selects columns based on datatype or the columns name with a regex. When using multiple selection criteria, all criteria must match for a column to be selected.\"\n",
    "3. `make_pipeline`\n",
    "> Used to create a pipeline of inputer transformer and estimator objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:17:55.295647Z",
     "start_time": "2021-11-17T04:17:55.289557Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing = make_column_transformer((BinAge(), ['age']),\n",
    "                                      (BinCapital(), ['capital-gain']),\n",
    "                                      (BinCapital(), ['capital-loss']),\n",
    "                                      (OneHotEncoder(sparse=False, handle_unknown='ignore'),\n",
    "                                       make_column_selector(dtype_include=object)),\n",
    "                                      (StandardScaler(), ['hours-per-week']),\n",
    "                                      remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:25:12.515850Z",
     "start_time": "2021-11-17T04:25:12.511491Z"
    }
   },
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "preprocessing = make_column_transformer((BinAge(), ['age']),\n",
    "                                      (BinCapital(), ['capital-gain']),\n",
    "                                      (BinCapital(), ['capital-loss']),\n",
    "                                      (OneHotEncoder(sparse=False, handle_unknown='ignore'),\n",
    "                                       make_column_selector(dtype_include=object)),\n",
    "                                      (StandardScaler(), ['hours-per-week']),\n",
    "                                      remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all of our preprocessing can be done with the `fit_transform` method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:18:21.604501Z",
     "start_time": "2021-11-17T04:18:21.468416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -2.87747181],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.77531045],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.20709987],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.03641894],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.28827281],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.77531045]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:18:22.376499Z",
     "start_time": "2021-11-17T04:18:22.287665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -2.87747181],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.77531045],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.20709987],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -0.03641894],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.28827281],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.77531045]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "preprocessing.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish up pipeline, we can add a machine learning model to a new pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:25:20.247664Z",
     "start_time": "2021-11-17T04:25:20.243952Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_pipeline = make_pipeline(preprocessing, DecisionTreeClassifier())\n",
    "rf_pipeline = make_pipeline(preprocessing, RandomForestClassifier(max_depth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:25:20.660307Z",
     "start_time": "2021-11-17T04:25:20.657142Z"
    }
   },
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "dt_pipeline = make_pipeline(preprocessing, DecisionTreeClassifier())\n",
    "rf_pipeline = make_pipeline(preprocessing, RandomForestClassifier(max_depth=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our pipelines are built!\n",
    "\n",
    "Now we can run them through cross validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:18:27.798352Z",
     "start_time": "2021-11-17T04:18:26.180613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80400364, 0.80709736, 0.80436761, 0.81598107, 0.8054241 ])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dt_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:18:29.643239Z",
     "start_time": "2021-11-17T04:18:28.067544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80327571, 0.80509554, 0.80691538, 0.815253  , 0.8076083 ])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "cross_val_score(dt_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:18:36.798975Z",
     "start_time": "2021-11-17T04:18:29.925812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83421292, 0.83202912, 0.82911738, 0.8401893 , 0.82981434])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:18:43.792523Z",
     "start_time": "2021-11-17T04:18:37.084160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83730664, 0.83184713, 0.8300273 , 0.83891518, 0.83163451])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "cross_val_score(rf_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:19:00.280763Z",
     "start_time": "2021-11-17T04:18:58.103221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.843155097732319\n",
      "Validation Accuracy: 0.8389386328892772\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline.fit(X_train, y_train)\n",
    "train_preds = rf_pipeline.predict(X_train)\n",
    "val_preds = rf_pipeline.predict(X_val)\n",
    "print(f'Training Accuracy: {accuracy_score(y_train, train_preds)}')\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, val_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:19:09.687190Z",
     "start_time": "2021-11-17T04:19:07.447140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.843955883958796\n",
      "Validation Accuracy: 0.8394846036252457\n"
     ]
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "train_preds = rf_pipeline.predict(X_train)\n",
    "val_preds = rf_pipeline.predict(X_val)\n",
    "print(f'Training Accuracy: {accuracy_score(y_train, train_preds)}')\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val, val_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can fit the final pipeline on all of the data and test it on an additional hold out set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:19:14.903308Z",
     "start_time": "2021-11-17T04:19:12.364886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('functiontransformer-1',\n",
       "                                                  FunctionTransformer(func=<numpy.vectorize object at 0x7f9898529550>),\n",
       "                                                  ['age']),\n",
       "                                                 ('functiontransformer-2',\n",
       "                                                  FunctionTransformer(func=<numpy.vectorize object at 0x7f9875de7950>),\n",
       "                                                  ['capital-gain']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f9898529610>),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['hours-per-week'])])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=10))])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline.fit(df.drop('income', axis = 1), df.income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:19:17.520201Z",
     "start_time": "2021-11-17T04:19:15.186360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('functiontransformer-1',\n",
       "                                                  FunctionTransformer(func=<numpy.vectorize object at 0x7f9898529550>),\n",
       "                                                  ['age']),\n",
       "                                                 ('functiontransformer-2',\n",
       "                                                  FunctionTransformer(func=<numpy.vectorize object at 0x7f9875de7950>),\n",
       "                                                  ['capital-gain']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f9898529610>),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['hours-per-week'])])),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(max_depth=10))])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "rf_pipeline.fit(df.drop('income', axis = 1), df.income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the hold out set and make predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:21:07.736570Z",
     "start_time": "2021-11-17T04:21:07.492289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8398165588403899"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import holdout data\n",
    "test = pd.read_csv('data/test.csv')\n",
    "# Seperate features from the target\n",
    "X_test, y_test = test.drop(columns=['income']), test.income\n",
    "# Score the model\n",
    "rf_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:21:16.091191Z",
     "start_time": "2021-11-17T04:21:15.867957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8398165588403899"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "# Import holdout data\n",
    "test = pd.read_csv('data/test.csv')\n",
    "# Seperate features from the target\n",
    "X_test, y_test = test.drop(columns=['income']), test.income\n",
    "# Score the model\n",
    "rf_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:25:30.145471Z",
     "start_time": "2021-11-17T04:25:26.882775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge training and hold out sets\n",
    "full_data = pd.concat([df, test])\n",
    "\n",
    "# Seperate the features from the target\n",
    "X, y = df.drop(columns=['income']), df.income\n",
    "\n",
    "# Fit the model to *all* observations\n",
    "rf_pipeline.fit(X, y)\n",
    "\n",
    "# Save the fit model to disk\n",
    "file = open('model_v1.pkl', 'wb')\n",
    "pickle.dump(rf_pipeline, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__SOLUTION__\n",
    "# Merge training and hold out sets\n",
    "full_data = pd.concat([df, test])\n",
    "\n",
    "# Seperate the features from the target\n",
    "X, y = df.drop(columns=['income']), df.income\n",
    "\n",
    "# Fit the model to *all* observations\n",
    "rf_pipeline.fit(X, y)\n",
    "\n",
    "# Save the fit model to disk\n",
    "file = open('model_v1.pkl', 'wb')\n",
    "pickle.dump(rf_pipeline, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the saved model works when loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:29:37.922591Z",
     "start_time": "2021-11-17T04:29:37.378077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['>50K', '<=50K', '<=50K', ..., '<=50K', '<=50K', '<=50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "file = open('model_v1.pkl', 'rb')\n",
    "model = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# Generate predictions\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T04:30:52.237909Z",
     "start_time": "2021-11-17T04:30:51.818063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['>50K', '<=50K', '<=50K', ..., '<=50K', '<=50K', '<=50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#__SOLUTION__\n",
    "# Load the model\n",
    "file = open('model_v1.pkl', 'rb')\n",
    "model = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# Generate predictions\n",
    "model.predict(X)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mlearn",
   "language": "python",
   "name": "mlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
